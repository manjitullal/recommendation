{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "collaborative-filtering-nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjitullal/recommendation/blob/main/collaborative_filtering_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM6EtTgEIQpp"
      },
      "source": [
        "# Collaborative Filtering with Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzrQG4eKIQpq"
      },
      "source": [
        "In this notebook we will write a matrix factorization model in pytorch to solve a recommendation problem. Then we will write a more general neural model for the same problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbUAN-5hIQpq"
      },
      "source": [
        "The MovieLens dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100004 ratings and 1296 tag applications across 9125 movies. https://grouplens.org/datasets/movielens/. To get the data:\n",
        "\n",
        "`wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O6YJJcsIQpq"
      },
      "source": [
        "## MovieLens dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUlcU-HiIQpq"
      },
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq_904ADIQpq",
        "outputId": "7d01f4f9-65b5-4b46-c596-08a205c0c71a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUrtAAfwIQpr"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/datasets/ml-latest-small/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNA6JnItIQps"
      },
      "source": [
        "data = pd.read_csv(PATH+\"ratings.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "-ixJ0FrSIQps",
        "outputId": "25b5b46c-c2d4-4c91-de9a-4f7de8387b35"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2AICnVyIQps"
      },
      "source": [
        "### Encoding data\n",
        "We enconde the data to have contiguous ids for users and movies. You can think about this as a categorical encoding of our two categorical variables userId and movieId."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlD_2UktIQps"
      },
      "source": [
        "# split train and validation before encoding\n",
        "np.random.seed(3)\n",
        "msk = np.random.rand(len(data)) < 0.8\n",
        "train = data[msk].copy()\n",
        "val = data[~msk].copy()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8ItKW5tIQps"
      },
      "source": [
        "# here is a handy function modified from fast.ai\n",
        "def proc_col(col, train_col=None):\n",
        "    \"\"\"Encodes a pandas column with continous ids. \n",
        "    \"\"\"\n",
        "    if train_col is not None:\n",
        "        uniq = train_col.unique()\n",
        "    else:\n",
        "        uniq = col.unique()\n",
        "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
        "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1u50pTtIQps"
      },
      "source": [
        "def encode_data(df, train=None):\n",
        "    \"\"\" Encodes rating data with continous user and movie ids. \n",
        "    If train is provided, encodes df with the same encoding as train.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    for col_name in [\"userId\", \"movieId\"]:\n",
        "        train_col = None\n",
        "        if train is not None:\n",
        "            train_col = train[col_name]\n",
        "        _,col,_ = proc_col(df[col_name], train_col)\n",
        "        df[col_name] = col\n",
        "        df = df[df[col_name] >= 0]\n",
        "    return df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfzfgx8tIQps"
      },
      "source": [
        "# encoding the train and validation data\n",
        "df_train = encode_data(train)\n",
        "df_val = encode_data(val, train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXD8_Dp_IQps"
      },
      "source": [
        "## Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdTL_-g9IQps"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzTGKWHPIQps"
      },
      "source": [
        "# an Embedding module containing 10 user or item embedding size 3\n",
        "# embedding will be initialized at random\n",
        "embed = nn.Embedding(10, 3)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKsJzkl-IQps",
        "outputId": "0a37880d-8494-4ffa-d833-b5d9ab641f37"
      },
      "source": [
        "# given a list of ids we can \"look up\" the embedding corresponing to each id\n",
        "a = torch.LongTensor([[1,2,0,4,5,1]])\n",
        "embed(a)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.7416,  0.9429, -0.0751],\n",
              "         [-0.0500, -0.7619, -0.6172],\n",
              "         [-0.0184,  0.8003,  1.4948],\n",
              "         [-0.0960,  0.2742, -0.4801],\n",
              "         [-0.5618, -0.1589,  0.3603],\n",
              "         [-0.7416,  0.9429, -0.0751]]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0-C4Gs9IQpt"
      },
      "source": [
        "## Matrix factorization model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5pp1YGWIQpt"
      },
      "source": [
        "class MF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100):\n",
        "        super(MF, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.user_emb.weight.data.uniform_(0, 0.05)\n",
        "        self.item_emb.weight.data.uniform_(0, 0.05)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        u = self.user_emb(u)\n",
        "        v = self.item_emb(v)\n",
        "        return (u*v).sum(1)   "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIa-ITd-IQpt"
      },
      "source": [
        "## Training MF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyVAXtd_IQpt",
        "outputId": "802815dd-0528-4540-85a5-4fd39ae5a4ee"
      },
      "source": [
        "num_users = len(df_train.userId.unique())\n",
        "num_items = len(df_train.movieId.unique())\n",
        "print(num_users, num_items) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "610 8998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzeVWOtyIQpu"
      },
      "source": [
        "model = MF(num_users, num_items, emb_size=100) # .cuda() if you have a GPU"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ifCqWGEIQpu"
      },
      "source": [
        "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for i in range(epochs):\n",
        "        users = torch.LongTensor(df_train.userId.values) # .cuda()\n",
        "        items = torch.LongTensor(df_train.movieId.values) #.cuda()\n",
        "        ratings = torch.FloatTensor(df_train.rating.values) #.cuda()\n",
        "        if unsqueeze:\n",
        "            ratings = ratings.unsqueeze(1)\n",
        "        y_hat = model(users, items)\n",
        "        loss = F.mse_loss(y_hat, ratings)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss.item()) \n",
        "    test_loss(model, unsqueeze)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na9675usIQpu",
        "outputId": "63328ea8-5586-484e-c312-476f2eb696ca"
      },
      "source": [
        "# Here is what unsqueeze does\n",
        "ratings = torch.FloatTensor(df_train.rating.values)\n",
        "print(ratings.shape)\n",
        "ratings = ratings.unsqueeze(1) # .cuda()\n",
        "print(ratings.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([80450])\n",
            "torch.Size([80450, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUzU-MqIQpu"
      },
      "source": [
        "def test_loss(model, unsqueeze=False):\n",
        "    model.eval()\n",
        "    users = torch.LongTensor(df_val.userId.values) #.cuda()\n",
        "    items = torch.LongTensor(df_val.movieId.values) #.cuda()\n",
        "    ratings = torch.FloatTensor(df_val.rating.values) #.cuda()\n",
        "    if unsqueeze:\n",
        "        ratings = ratings.unsqueeze(1)\n",
        "    y_hat = model(users, items)\n",
        "    loss = F.mse_loss(y_hat, ratings)\n",
        "    print(\"test loss %.3f \" % loss.item())"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRCB4RPDIQpu",
        "outputId": "99dd0347-e895-401b-ecf2-e41c748b895a"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.913166999816895\n",
            "4.8541460037231445\n",
            "2.57963490486145\n",
            "3.1019914150238037\n",
            "0.848253071308136\n",
            "1.8178449869155884\n",
            "2.651867151260376\n",
            "2.1297454833984375\n",
            "1.0853337049484253\n",
            "0.9746541976928711\n",
            "test loss 1.850 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQjnfgCHGWRs"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "This is straigthforward, we pick a user and find the movies not rated by the user. Convert the user and the list of non rated movies as tensors and then pass to the model to get the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p8bCnuLD83V",
        "outputId": "c6693e3d-aa4a-4d18-f29c-fa36a943dd58"
      },
      "source": [
        "# predict \n",
        "\n",
        "movies_ratedby_1 = data[data.userId == 1]['movieId'].values\n",
        "movies_notratedby_1 = list(set(data.movieId.values.tolist()) - set(movies_ratedby_1.tolist()))\n",
        "\n",
        "print(len(movies_ratedby_1), len(movies_notratedby_1))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "232 9492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQq2i155Fo6m",
        "outputId": "594fd782-a230-4a4a-d770-cfb4c62614f5"
      },
      "source": [
        "# movies_notratedby_1[0:5]\n",
        "# [2, 4, 5, 7, 8]\n",
        "\n",
        "user = torch.LongTensor([1])\n",
        "items = torch.LongTensor([2, 4, 5, 7, 8])\n",
        "predicted_rating = model(user, items)\n",
        "print(predicted_rating)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4.2586, 4.4711, 4.4432, 3.7018, 3.9871], grad_fn=<SumBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZvl9Pe3IQpu",
        "outputId": "d6f04bd2-b8c6-47f3-8f01-4009325751ae"
      },
      "source": [
        "train_epocs(model, epochs=15, lr=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6432433128356934\n",
            "1.004770278930664\n",
            "0.711879551410675\n",
            "0.6606624126434326\n",
            "0.7254241108894348\n",
            "0.8038312792778015\n",
            "0.8437075614929199\n",
            "0.8357229828834534\n",
            "0.7934749722480774\n",
            "0.7378419041633606\n",
            "0.6878331899642944\n",
            "0.6556430459022522\n",
            "0.6445807218551636\n",
            "0.6497317552566528\n",
            "0.6612839698791504\n",
            "test loss 0.821 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUbOpStPIQpu",
        "outputId": "91b2d4ec-8eb7-4532-c89f-984e8274b639"
      },
      "source": [
        "train_epocs(model, epochs=15, lr=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6693901419639587\n",
            "0.6312034130096436\n",
            "0.6390069723129272\n",
            "0.614273190498352\n",
            "0.6052837371826172\n",
            "0.6137663722038269\n",
            "0.6116158366203308\n",
            "0.5968126058578491\n",
            "0.5848029255867004\n",
            "0.5829773545265198\n",
            "0.5840793251991272\n",
            "0.5791772603988647\n",
            "0.5685186386108398\n",
            "0.5582433342933655\n",
            "0.5519680380821228\n",
            "test loss 0.759 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbuW3Nw5Qqa_",
        "outputId": "f1b6ccc9-d91d-4999-8614-3fc5b9632829"
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of MF_bias(\n",
              "  (user_emb): Embedding(610, 100)\n",
              "  (user_bias): Embedding(610, 1)\n",
              "  (item_emb): Embedding(8998, 100)\n",
              "  (item_bias): Embedding(8998, 1)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3_-GgxYRZl3",
        "outputId": "2fba4776-a182-426c-addf-15f060396e94"
      },
      "source": [
        "len(train.userId.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U9AQfCSRxPt"
      },
      "source": [
        "movies_watched = train[train.userId == 1].movieId.values\n",
        "movies_not_watched = list(set(train.movieId.values.flatten()) - set(movies_watched.flatten()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5-HTSCtIQpu"
      },
      "source": [
        "## MF with bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czzIc_JaIQpu"
      },
      "source": [
        "class MF_bias(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100):\n",
        "        super(MF_bias, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.user_bias = nn.Embedding(num_users, 1)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.item_bias = nn.Embedding(num_items, 1)\n",
        "        self.user_emb.weight.data.uniform_(0,0.05)\n",
        "        self.item_emb.weight.data.uniform_(0,0.05)\n",
        "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
        "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        V = self.item_emb(v)\n",
        "        b_u = self.user_bias(u).squeeze()\n",
        "        b_v = self.item_bias(v).squeeze()\n",
        "        return (U*V).sum(1) +  b_u  + b_v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1Fgq6UyIQpu"
      },
      "source": [
        "model = MF_bias(num_users, num_items, emb_size=100) #.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2vz_dwzIQpu",
        "outputId": "2271d706-7c67-427f-9f01-361a66a11497"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.05, wd=1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.908324241638184\n",
            "9.145543098449707\n",
            "4.37777853012085\n",
            "1.1558018922805786\n",
            "2.4738709926605225\n",
            "3.7419700622558594\n",
            "2.444751262664795\n",
            "1.0767680406570435\n",
            "0.8169639706611633\n",
            "1.3199241161346436\n",
            "test loss 2.070 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92YYbWGcIQpu",
        "outputId": "15b32f8a-5e8c-4f3b-83d1-c7f5cafea6f4"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.01, wd=1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.894714117050171\n",
            "1.3260996341705322\n",
            "0.9358387589454651\n",
            "0.7452532649040222\n",
            "0.7224956154823303\n",
            "0.7773878574371338\n",
            "0.8229359984397888\n",
            "0.8220500946044922\n",
            "0.7816600203514099\n",
            "0.7278069853782654\n",
            "test loss 0.798 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SBKBYVnIQpu",
        "outputId": "de63671b-31fd-491b-c928-6417e82ba754"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.001, wd=1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6854904890060425\n",
            "0.6712726354598999\n",
            "0.6593731045722961\n",
            "0.6496144533157349\n",
            "0.6417774558067322\n",
            "0.635627269744873\n",
            "0.6309210658073425\n",
            "0.6274157762527466\n",
            "0.6248804330825806\n",
            "0.6231045126914978\n",
            "test loss 0.751 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWQMU-ARIQpu"
      },
      "source": [
        "Note that these models are susceptible to weight initialization, optimization algorithm and regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqh5o1XHIQpu"
      },
      "source": [
        "## Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UL-frTcIQpu"
      },
      "source": [
        "# Note here there is no matrix multiplication, we could potentially make the embeddings of different sizes.\n",
        "# Here we could get better results by keep playing with regularization.\n",
        "    \n",
        "class CollabFNet(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
        "        super(CollabFNet, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
        "        self.lin2 = nn.Linear(n_hidden, 1)\n",
        "        self.drop1 = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        V = self.item_emb(v)\n",
        "        x = F.relu(torch.cat([U, V], dim=1))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU4dH6KCIQpu"
      },
      "source": [
        "model = CollabFNet(num_users, num_items, emb_size=100) #.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3W4YSbgIQpu",
        "outputId": "bc275e5d-27b3-44cb-9271-21b0874fef54"
      },
      "source": [
        "train_epocs(model, epochs=15, lr=0.05, wd=1e-6, unsqueeze=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13.434941291809082\n",
            "16.370405197143555\n",
            "1.3257286548614502\n",
            "5.508914470672607\n",
            "6.2165207862854\n",
            "4.431434154510498\n",
            "2.1724636554718018\n",
            "1.1197346448898315\n",
            "1.831865906715393\n",
            "2.8045129776000977\n",
            "2.4782402515411377\n",
            "1.460442066192627\n",
            "0.932476282119751\n",
            "1.0870381593704224\n",
            "1.4916064739227295\n",
            "test loss 1.760 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIl7Sy08IQpv",
        "outputId": "6d4284d4-a368-47f8-bd44-035456602a2d"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.01, wd=1e-6, unsqueeze=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7271547317504883\n",
            "0.938242495059967\n",
            "0.888296902179718\n",
            "1.159741997718811\n",
            "1.1197892427444458\n",
            "0.9154775738716125\n",
            "0.7834805250167847\n",
            "0.7914189696311951\n",
            "0.8674263954162598\n",
            "0.9142893552780151\n",
            "test loss 0.938 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O95c3atIQpv",
        "outputId": "fe335bad-d1da-4660-b88e-2dc9b642604a"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.001, wd=1e-6, unsqueeze=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8928335905075073\n",
            "0.8472162485122681\n",
            "0.8096950054168701\n",
            "0.7786527872085571\n",
            "0.7578306198120117\n",
            "0.7424415349960327\n",
            "0.7362892031669617\n",
            "0.7386234402656555\n",
            "0.7381541132926941\n",
            "0.7439978718757629\n",
            "test loss 0.797 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyN3dZalIQpv",
        "outputId": "f9e7e605-859c-442a-cdf3-42d9f36555c2"
      },
      "source": [
        "train_epocs(model, epochs=10, lr=0.001, wd=1e-6, unsqueeze=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6919353008270264\n",
            "0.6934647560119629\n",
            "0.6922585368156433\n",
            "0.6942275762557983\n",
            "0.6926798224449158\n",
            "0.6916202902793884\n",
            "0.6911264061927795\n",
            "0.6923496127128601\n",
            "0.6922929286956787\n",
            "0.6904215812683105\n",
            "test loss 0.795 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}